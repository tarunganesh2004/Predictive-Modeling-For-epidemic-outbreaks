{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date      country  cumulative_total_cases  daily_new_cases  \\\n",
      "0  2020-2-15  Afghanistan                     0.0              NaN   \n",
      "1  2020-2-16  Afghanistan                     0.0              NaN   \n",
      "2  2020-2-17  Afghanistan                     0.0              NaN   \n",
      "3  2020-2-18  Afghanistan                     0.0              NaN   \n",
      "4  2020-2-19  Afghanistan                     0.0              NaN   \n",
      "\n",
      "   active_cases  cumulative_total_deaths  daily_new_deaths  \n",
      "0           0.0                      0.0               NaN  \n",
      "1           0.0                      0.0               NaN  \n",
      "2           0.0                      0.0               NaN  \n",
      "3           0.0                      0.0               NaN  \n",
      "4           0.0                      0.0               NaN  \n",
      "Index(['date', 'country', 'cumulative_total_cases', 'daily_new_cases',\n",
      "       'active_cases', 'cumulative_total_deaths', 'daily_new_deaths'],\n",
      "      dtype='object')\n",
      "Shape of X: (184766, 7, 5)\n",
      "Shape of y: (184766,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"worldometer_coronavirus_daily_data.csv\")  # Update with your dataset path\n",
    "\n",
    "# Inspect the first few rows and the columns\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "\n",
    "# Rename columns for Prophet model\n",
    "df.rename(columns={\"date\": \"ds\", \"cumulative_total_cases\": \"y\"}, inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "# Create new features\n",
    "# Ensure 'y' exists after renaming\n",
    "if \"y\" in df.columns:\n",
    "    df[\"moving_avg_7\"] = df[\"y\"].rolling(window=7).mean()  # 7-day moving average\n",
    "    df[\"moving_avg_14\"] = df[\"y\"].rolling(window=14).mean()  # 14-day moving average\n",
    "    df[\"lag_1\"] = df[\"y\"].shift(1)  # 1-day lag\n",
    "    df[\"lag_7\"] = df[\"y\"].shift(7)  # 7-day lag\n",
    "\n",
    "    # Drop rows with NaN values that may result from rolling operations\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Scale the features\n",
    "    features = df[[\"y\", \"moving_avg_7\", \"moving_avg_14\", \"lag_1\", \"lag_7\"]].values\n",
    "    scaler = MinMaxScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Prepare the dataset for the CNN model\n",
    "    def create_dataset(data, time_step=1):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - time_step - 1):\n",
    "            a = data[i : (i + time_step)]\n",
    "            X.append(a)\n",
    "            y.append(data[i + time_step, 0])  # Target is the first column (y)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    time_step = 7  # Define the time step for the CNN input\n",
    "    X, y = create_dataset(features_scaled, time_step)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2])  # Reshape for CNN input\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "else:\n",
    "    print(\"Column 'y' not found. Check the renaming step.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.6\n"
     ]
    }
   ],
   "source": [
    "import prophet\n",
    "\n",
    "print(prophet.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:13:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:13:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Create and fit the Prophet model\n",
    "prophet_model = Prophet()\n",
    "prophet_model.fit(df[[\"ds\", \"y\"]])\n",
    "\n",
    "# Generate future dates for prediction\n",
    "future = prophet_model.make_future_dataframe(periods=30)  # Predict for 30 days\n",
    "forecast = prophet_model.predict(future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 08m 18s]\n",
      "val_loss: 6.641453364863992e-05\n",
      "\n",
      "Best val_loss So Far: 3.391817517695017e-05\n",
      "Total elapsed time: 02h 52m 12s\n",
      "Epoch 1/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.9545e-05 - val_loss: 6.1509e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.9611e-05 - val_loss: 4.1941e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.1339e-05 - val_loss: 8.7546e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7735e-05 - val_loss: 5.6807e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.1417e-05 - val_loss: 4.8077e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.4161e-05 - val_loss: 6.0701e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7329e-05 - val_loss: 4.4331e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.9575e-05 - val_loss: 3.9872e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.6291e-05 - val_loss: 4.8984e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.4250e-05 - val_loss: 7.0937e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.2014e-05 - val_loss: 4.3710e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.4039e-05 - val_loss: 9.5642e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.0115e-05 - val_loss: 3.6249e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.2408e-05 - val_loss: 4.8287e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.9924e-05 - val_loss: 1.3088e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 2.3052e-05 - val_loss: 3.6757e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 2.5886e-05 - val_loss: 4.0023e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 1.8753e-05 - val_loss: 7.1902e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 2.1856e-05 - val_loss: 3.9473e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.7878e-05 - val_loss: 4.5615e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.8334e-05 - val_loss: 3.9263e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6396e-05 - val_loss: 3.8008e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.1348e-05 - val_loss: 3.9799e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.0035e-05 - val_loss: 3.6976e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.0656e-05 - val_loss: 4.2974e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.6387e-05 - val_loss: 3.5776e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.3093e-05 - val_loss: 3.4263e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.9170e-05 - val_loss: 5.3072e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.1548e-05 - val_loss: 3.6877e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5879e-05 - val_loss: 3.5527e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.8269e-05 - val_loss: 5.5530e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.6651e-05 - val_loss: 5.8704e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.3266e-05 - val_loss: 3.6396e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5096e-05 - val_loss: 4.0340e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5652e-05 - val_loss: 3.6143e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.2328e-05 - val_loss: 3.4485e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.6396e-05 - val_loss: 4.1226e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.1584e-05 - val_loss: 9.6105e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.0882e-05 - val_loss: 4.1395e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.9742e-05 - val_loss: 3.6574e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.9038e-05 - val_loss: 3.4123e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.6031e-05 - val_loss: 3.3193e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.9936e-05 - val_loss: 3.6232e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.1805e-05 - val_loss: 4.4438e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.1235e-05 - val_loss: 3.3802e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.9282e-05 - val_loss: 6.7762e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.7380e-05 - val_loss: 3.6655e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.2232e-05 - val_loss: 3.7856e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.4777e-05 - val_loss: 3.8155e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m4620/4620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5875e-05 - val_loss: 4.0335e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x233854eb610>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras_tuner import Hyperband\n",
    "\n",
    "\n",
    "# Define the CNN model with hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv1D(\n",
    "            filters=hp.Int(\"filters\", 32, 128, step=16),\n",
    "            kernel_size=hp.Choice(\"kernel_size\", [2, 3, 5]),\n",
    "            activation=\"relu\",\n",
    "            input_shape=(X.shape[1], X.shape[2]),\n",
    "        )\n",
    "    )\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=hp.Int(\"units\", 32, 128, step=16), activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Tune hyperparameters using Keras Tuner\n",
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"cnn_tuning\",\n",
    ")\n",
    "tuner.search(X, y, epochs=50, validation_split=0.2)\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Train the best model\n",
    "best_model.fit(X, y, epochs=50, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m cnn_predictions \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(last_days)\n\u001b[0;32m      3\u001b[0m cnn_predictions \u001b[38;5;241m=\u001b[39m cnn_predictions\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape if output is 1D\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m cnn_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcnn_predictions\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Inverse transform to original scale\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\emada\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:574\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    564\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    566\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    567\u001b[0m     X,\n\u001b[0;32m    568\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    571\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    572\u001b[0m )\n\u001b[1;32m--> 574\u001b[0m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_\u001b[49m\n\u001b[0;32m    575\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,5)"
     ]
    }
   ],
   "source": [
    "# Assuming your model outputs a single value\n",
    "cnn_predictions = best_model.predict(last_days)\n",
    "cnn_predictions = cnn_predictions.reshape(-1, 1)  # Reshape if output is 1D\n",
    "cnn_predictions = scaler.inverse_transform(\n",
    "    cnn_predictions\n",
    ")  # Inverse transform to original scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict using the best CNN model\n",
    "last_days = features_scaled[-time_step:].reshape(\n",
    "    (1, time_step, features_scaled.shape[1])\n",
    ")\n",
    "\n",
    "# Get predictions from the CNN model\n",
    "cnn_predictions = best_model.predict(last_days)\n",
    "\n",
    "# Assuming the model outputs 1 prediction, create an array of 5 elements\n",
    "cnn_predictions = np.zeros(\n",
    "    (1, features_scaled.shape[1])\n",
    ")  # Create a placeholder for the right shape\n",
    "cnn_predictions[0, 0] = best_model.predict(last_days)  # Fill in the prediction\n",
    "\n",
    "# Inverse transform to original scale\n",
    "cnn_predictions = scaler.inverse_transform(cnn_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Shape of cnn_predictions: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict using the best CNN model\n",
    "last_days = features_scaled[-time_step:].reshape(\n",
    "    (1, time_step, features_scaled.shape[1])\n",
    ")\n",
    "\n",
    "cnn_predictions = best_model.predict(last_days)\n",
    "\n",
    "# Check the shape of cnn_predictions\n",
    "print(\n",
    "    \"Shape of cnn_predictions:\", cnn_predictions.shape\n",
    ")  # Add this line to check the output shape\n",
    "\n",
    "# If it is a single prediction, you may not need to reshape it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Shape of cnn_predictions: (1, 1)\n",
      "RMSE: 2202782.8987099985\n",
      "MAE: 2202285.9743201644\n"
     ]
    }
   ],
   "source": [
    "# Predict using the best CNN model\n",
    "last_days = features_scaled[-time_step:].reshape(\n",
    "    (1, time_step, features_scaled.shape[1])\n",
    ")\n",
    "\n",
    "cnn_predictions = best_model.predict(last_days)\n",
    "\n",
    "# Check the shape of cnn_predictions\n",
    "print(\"Shape of cnn_predictions:\", cnn_predictions.shape)\n",
    "\n",
    "# Since the output shape is (1, 1), extract the predicted value\n",
    "cnn_prediction_value = cnn_predictions[0, 0]  # Get the single prediction value\n",
    "\n",
    "# Expand to match the shape of forecast[\"yhat\"].values[-30:]\n",
    "cnn_prediction_expanded = np.full((30,), cnn_prediction_value)\n",
    "\n",
    "# Combine predictions and evaluate\n",
    "combined_predictions = forecast[\"yhat\"].values[-30:] + cnn_prediction_expanded\n",
    "\n",
    "# Calculate RMSE and MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "rmse = np.sqrt(\n",
    "    mean_squared_error(df[\"y\"][-30:], combined_predictions)\n",
    ")  # Use the last 30 days for evaluation\n",
    "mae = mean_absolute_error(df[\"y\"][-30:], combined_predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: -15028624.219175577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R²\n",
    "r2 = r2_score(df[\"y\"][-30:], combined_predictions)\n",
    "\n",
    "print(f\"R²: {r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
